import awaitTo from '@/utils/await-to-js'
import { getUserMedia, concatFloat32Array, createWavFile, mergeFloat32Arrays } from '@/utils/stream'
import { FixedQueue } from '@/utils/queue'

/**
 *
 * @param {object} #options å®ä¾‹åŒ–å®ä¾‹æ—¶ä¼ å…¥çš„å‚æ•°
 *
 */

class SoundVadClass {
  _options

  _average // çµæ•åº¦é˜ˆå€¼
  _analyserRate // åˆ†æå™¨é¢‘ç‡
  _sampleRate // é‡‡æ ·ç‡

  _mediaStreamSource = null // å½•éŸ³æµæº
  _streamAnalyser = null // åˆ†æå™¨
  _audioContext = null // éŸ³é¢‘ä¸Šä¸‹æ–‡
  _analyserTimer = null // åˆ†æå™¨å®šæ—¶å™¨
  _isSpeeching = false // æ˜¯å¦åœ¨è¯´è¯
  _recordPCMData = new Float32Array([]) // å½•éŸ³æ•°æ®
  _delayFrameCount = 0 // å»¶è¿Ÿå¸§è®¡æ•°
  _delayFrameLimit = 20 // å»¶è¿Ÿå¸§é™åˆ¶

  constructor({ average, analyserRate, sampleRate, ...options } = {}) {
    this._options = options
    this._sampleRate = sampleRate || 16000
    this._average = average || 35
    this._analyserRate = analyserRate || 50
  }

  get isSpeeching() {
    // é€šè¿‡getterè®¿é—®ç§æœ‰å­—æ®µ
    return this._isSpeeching
  }

  set isSpeeching(newName) {
    // é€šè¿‡setterä¿®æ”¹ç§æœ‰å­—æ®µ
    this._isSpeeching = newName
  }

  // è·å–æƒé™å¤±è´¥
  _handlePermissionError() {
    if (typeof this._options?.onPermissionError === 'function') {
      this._options.onPermissionError()
    }
  }

  // vadçŠ¶æ€å›è°ƒ
  _handleVadStatus(data) {
    if (typeof this._options?.onVadStatus === 'function') {
      this._options.onVadStatus(data)
    }
  }

  // ç›‘å¬éŸ³é¢‘æ•°æ®
  _handleListenAudioData(data) {
    if (typeof this._options?.onListenAudioData === 'function') {
      this._options.onListenAudioData(data)
    }
  }

  // æ¸…ç†å½•éŸ³æ•°æ®
  clearRecordPCMData() {
    this._recordPCMData = new Float32Array([])
  }

  // è·å–å½•éŸ³æ•°æ®
  getRecordWavData() {
    return createWavFile(this._recordPCMData, this._sampleRate)
  }

  // å¼€å¯å£°éŸ³ç›‘å¬
  async startListen({ isClientVad = true }) {
    // è·å–ç”¨æˆ·åª’ä½“æµ with proper iOS-compatible constraints
    const constraints = {
      audio: {
        echoCancellation: true,       // Request AEC
        noiseSuppression: true,       // Request noise suppression
        autoGainControl: true,        // Request AGC
        voiceIsolation: true,         // iOS 17+ voice isolation
        channelCount: 1,              // Mono channel
        sampleRate: 48000,            // Safari is fine with 48k, better compatibility
      },
      video: false
    }
    
    // è·å–ç”¨æˆ·åª’ä½“æµ
    const [err, stream] = await awaitTo(
      getUserMedia(constraints)
    )
    if (err) {
      this._handlePermissionError() // è·å–æƒé™å¤±è´¥
      return
    }
    
    // Debug: Verify Safari/iOS honored the constraints we requested
    const [track] = stream.getAudioTracks()
    const settings = track.getSettings()
    const isIOS = /iPhone|iPad|iPod/.test(navigator.userAgent) || 
                  (/Mac/.test(navigator.userAgent) && navigator.maxTouchPoints > 1);
    
    console.log('ğŸ¤ [SoundVad] Microphone initialized');
    console.log('ğŸ“± [SoundVad] Platform:', isIOS ? 'iOS/iPadOS' : 'Other');
    console.log('ğŸ”§ [SoundVad] All mic settings:', settings);
    console.log('âœ… [SoundVad] Echo cancellation:', settings.echoCancellation);
    console.log('âœ… [SoundVad] Noise suppression:', settings.noiseSuppression);
    console.log('âœ… [SoundVad] Auto gain control:', settings.autoGainControl);
    console.log('âœ… [SoundVad] Voice isolation:', settings.voiceIsolation || 'not supported');

    // Try to re-apply constraints if they weren't honored (iOS Safari quirk)
    if (settings.echoCancellation !== true) {
      console.warn('âš ï¸ [SoundVad] Echo cancellation was NOT enabled! Attempting to re-apply...');
      try {
        await track.applyConstraints({ 
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        })
        const newSettings = track.getSettings();
        console.log('ğŸ”„ [SoundVad] Re-applied constraints. Echo cancellation now:', newSettings.echoCancellation);
      } catch (applyErr) {
        console.error('âŒ [SoundVad] FAILED to apply echo cancellation:', applyErr);
      }
    } else {
      console.log('âœ… [SoundVad] Echo cancellation already enabled!');
    }

    // Try to apply voiceIsolation if supported (iOS 17+)
    if (isIOS && settings.voiceIsolation !== true) {
      try {
        await track.applyConstraints({ voiceIsolation: true })
        console.log('ğŸ™ï¸ [SoundVad] Applied voiceIsolation (iOS 17+)');
      } catch (applyErr) {
        // voiceIsolation might not be supported on older iOS versions - this is OK
        console.log('â„¹ï¸ [SoundVad] Voice isolation not available (requires iOS 17+)');
      }
    }

    let inputBuffer = null // åŸå§‹é€šé“æ•°æ®
    const bufferSize = isClientVad ? 4096 : 2048 // ç¼“å†²åŒºå¤§å°
    const vadFrame = isClientVad ? 3 : 6 // å¸§ï¼Œæ¯å¸§4 * 1536 byteï¼Œçº¦ä¸º100msï¼Œç”¨äºVADæ£€æµ‹çš„æœ‰æ•ˆç‰‡æ®µ
    const aheadChunks = new FixedQueue(vadFrame) // é˜Ÿåˆ—ï¼Œç”¨äºç¼“å­˜éŸ³é¢‘æ•°æ®
    this._audioContext = new (window.AudioContext ||
      window.webkitAudioContext ||
      window.mozAudioContext)({ sampleRate: this._sampleRate })
    // åˆ›å»ºè„šæœ¬å¤„ç†èŠ‚ç‚¹
    this._scriptProcessorNode = this._audioContext.createScriptProcessor(bufferSize, 1, 1)
    // å½“éŸ³é¢‘æ•°æ®å¯ç”¨æ—¶æ‰§è¡Œçš„å›è°ƒå‡½æ•°
    this._scriptProcessorNode.onaudioprocess = async ev => {
      inputBuffer = ev.inputBuffer.getChannelData(0)
      if (inputBuffer && inputBuffer.length > 0) {
        if (isClientVad) {
          if (this._isSpeeching) {
            if (aheadChunks.length > 0) {
              // å¤„ç†é¢„åˆ¶çš„éŸ³é¢‘æ•°æ®
              const aheadChunksData = aheadChunks.getQueue().reduce((a, b) => {
                return concatFloat32Array(a, b)
              }, new Float32Array([]))
              inputBuffer = concatFloat32Array(aheadChunksData, inputBuffer)
              aheadChunks.clear()
            }
            this._recordPCMData = concatFloat32Array(this._recordPCMData, inputBuffer)
            const wavBlob = createWavFile(inputBuffer, this._sampleRate)
            this._handleListenAudioData(wavBlob)
          } else {
            aheadChunks.append(new Float32Array(inputBuffer))
          }
        } else {
          if (this._isSpeeching) {
            if (aheadChunks.length) {
              const aheadChunksData = mergeFloat32Arrays(aheadChunks.getQueue())
              this._recordPCMData = concatFloat32Array(aheadChunksData, this._recordPCMData)
              aheadChunks.clear()
            }
            this._recordPCMData = concatFloat32Array(this._recordPCMData, inputBuffer)
          } else {
            aheadChunks.append(new Float32Array(inputBuffer))
          }
          const wavBlob = createWavFile(inputBuffer, this._sampleRate)
          this._handleListenAudioData(wavBlob)
        }
      }
    }

    // åˆ›å»ºå½•éŸ³åª’ä½“æµæº
    this._mediaStreamSource = this._audioContext.createMediaStreamSource(stream)
    // åˆ›å»ºéŸ³é¢‘å¢ç›ŠèŠ‚ç‚¹
    this._gainNode = this._audioContext.createGain()
    // åˆ›å»ºéŸ³é¢‘è¾“å‡ºèŠ‚ç‚¹
    this._destAudioNode = this._audioContext.createMediaStreamDestination()
    // å¢ç›ŠèŠ‚ç‚¹è¿æ¥è„šæœ¬å¤„ç†èŠ‚ç‚¹ï¼Œè¿æ¥éŸ³é¢‘è¾“å‡ºèŠ‚ç‚¹
    this._gainNode.connect(this._scriptProcessorNode).connect(this._destAudioNode)

    // åª’ä½“æµæºè¿æ¥å¢ç›ŠèŠ‚ç‚¹
    this._mediaStreamSource.connect(this._gainNode)
    // // å¢ç›ŠèŠ‚ç‚¹è¿æ¥è¾“å‡ºèŠ‚ç‚¹
    // audioNode.connect(this._destAudioNode)

    if (isClientVad) {
      // å¯ç”¨vad
      // åˆ›å»ºåˆ†æå™¨èŠ‚ç‚¹
      this._streamAnalyser = this._audioContext.createAnalyser()
      // åª’ä½“æµæºè¿æ¥åˆ†æå™¨
      this._mediaStreamSource.connect(this._streamAnalyser)
      // è®¾å®šåˆ†æå™¨å‚æ•°
      this._streamAnalyser.fftSize = 2048
      const bufferLength = this._streamAnalyser.frequencyBinCount
      const dataArray = new Uint8Array(bufferLength)

      // å®šæ—¶æ£€æµ‹éŸ³é¢‘æ•°æ®
      this._analyserTimer = setInterval(() => {
        this._streamAnalyser.getByteFrequencyData(dataArray)
        let sum = 0
        for (let i = 0; i < bufferLength; i++) {
          sum += dataArray[i]
        }
        const average = sum / bufferLength
        if (average > this._average) {
          // ç®€å•é˜ˆå€¼åˆ¤æ–­ï¼Œå¯æ ¹æ®å®é™…è°ƒæ•´
          this._isSpeeching = true
          this._delayFrameCount = 0
        } else if (average < this._average) {
          this._delayFrameCount++
          if (this._delayFrameCount > this._delayFrameLimit) {
            this._isSpeeching = false
          }
        }
        this._handleVadStatus(this._isSpeeching)
        // console.log('--average--', average)
      }, this._analyserRate)
    }
  }

  // åœæ­¢å£°éŸ³ç›‘å¬
  closeListen() {
    // é‡Šæ”¾VADç›¸å…³èµ„æº
    if (this._analyserTimer) {
      clearInterval(this._analyserTimer)
    }
    try {
      if (this._gainNode && this._scriptProcessorNode && this._destAudioNode) {
        // this._gainNode.disconnect(this._scriptProcessorNode)
        // this._gainNode.disconnect(this._destAudioNode)
        this._scriptProcessorNode.onaudioprocess = null
        this._scriptProcessorNode = null
        this._destAudioNode = null
      }
      if (this._mediaStreamSource && this._streamAnalyser && this._gainNode) {
        this._mediaStreamSource.disconnect(this._gainNode)
        this._mediaStreamSource.disconnect(this._streamAnalyser)
        // é‡Šæ”¾MediaStream
        const tracks = this._mediaStreamSource.mediaStream.getTracks()
        tracks.forEach(track => track.stop())
        this._mediaStreamSource = null
        this._streamAnalyser = null
        this._gainNode = null
      }
    } catch (e) {
      console.error('closeListen', e)
    }
    this._audioContext = null
    this._isSpeeching = false
    this._recordPCMData = new Float32Array([])
    this._delayFrameCount = 0
    this._handleVadStatus(false)
  }
}

export default SoundVadClass
